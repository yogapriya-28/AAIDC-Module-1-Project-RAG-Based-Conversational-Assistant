# ğŸ§  RAG-Based Conversational Assistant for Ready Tensor Publications  
**AAIDC Project 1**  
**License:** Creative Commons Attributionâ€“NonCommercial (CC BYâ€“NC)

---

## ğŸ“ Abstract  
This project presents a **Retrieval-Augmented Generation (RAG)**â€“based conversational assistant designed to answer questions grounded in **Ready Tensor publications**.  
It integrates document ingestion, semantic embedding, and retrieval with **Large Language Models (LLMs)** to produce contextually accurate, grounded answers.

The system demonstrates an **end-to-end Agentic AI pipeline** capable of retrieving relevant publication excerpts and generating coherent, factually consistent responses â€” showcasing how retrieval-based grounding enhances generative reasoning.

---

## ğŸ“– Introduction  
As part of the **AAIDC Module 1 â€“ Foundations of Agentic AI**, this project explores how retrieval mechanisms improve factual accuracy in conversational AI.

The RAG architecture combines **semantic search** and **generative reasoning**, making it ideal for building domain-specific assistants such as academic, research, or corporate knowledge chatbots.

This implementation specifically focuses on **35 Ready Tensor publications** to enable a contextual questionâ€“answering system.

---

## ğŸ¯ Objectives  
- Ingest 35 Ready Tensor publications (`project_1_publications.json`)  
- Generate semantic embeddings using **text-embedding-3-small**  
- Implement **FAISS-based retriever** for efficient similarity search  
- Integrate **ChatOpenAI (GPT-3.5-Turbo)** for grounded LLM responses  
- Provide two user interfaces:  
  ğŸ’» **Notebook Chat Widget (ipywidgets)**  
  ğŸŒ **Streamlit Web App**

---

## ğŸ§© System Architecture  

```plaintext
ğŸ“„ project_1_publications.json
        â”‚
        â–¼
ğŸ§  RecursiveCharacterTextSplitter
        â”‚
        â–¼
ğŸ’¾ OpenAI text-embedding-3-small
        â”‚
        â–¼
ğŸ—‚ï¸ FAISS Vector Store
        â”‚
        â–¼
ğŸ” LangChain Retriever + PromptTemplate
        â”‚
        â–¼
ğŸ¤– ChatOpenAI (GPT-3.5-Turbo)
        â”‚
        â–¼
ğŸ’¬ Streamlit + Chat Widget UI

---

## âš™ï¸ Core Components
 
| Component           | Description                 |
| ------------------- | --------------------------- |
| **Framework**       | LangChain                   |
| **Vector DB**       | FAISS                       |
| **Embedding Model** | text-embedding-3-small      |
| **LLM**             | GPT-3.5-Turbo               |
| **UI Frameworks**   | Streamlit, ipywidgets       |
| **Environment**     | Google Colab                |
| **License**         | Creative Commons (CC BYâ€“NC) |

---

## ğŸ“Š Dataset & Retrieval

| Component           | Description                      |
| ------------------- | -------------------------------- |
| **Dataset**         | 35 Ready Tensor Publications     |
| **Chunking**        | 1000 characters with 150 overlap |
| **Embeddings**      | OpenAI `text-embedding-3-small`  |
| **Retriever**       | FAISS vector search (Top-3)      |
| **Prompt Template** | Context-aware retrieval          |
| **Memory**          | ConversationBufferMemory         |
| **LLM**             | GPT-3.5-Turbo                    |
| **Interfaces**      | ipywidgets + Streamlit           |

---

## ğŸ’¬ Example Queries
Try these inside your assistant:
- â€œWhich Ready Tensor article discusses RAG evaluation methods?â€
- â€œWho authored the Agentic AI course modules?â€
- â€œWhat are the goals of the AAIDC certification?â€



---

## ğŸš€ How to Run

1ï¸âƒ£ Upload `project_1_publications.json`  
2ï¸âƒ£ Set your OpenAI API key:
```python
os.environ["OPENAI_API_KEY"] = "your-key"
